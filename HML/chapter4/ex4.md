# Do all gradient descent algorithms lead to the same model, provided you let them run long enough?

No, the stochastic itself will never converge, when the Batch gradient will converge to one point.

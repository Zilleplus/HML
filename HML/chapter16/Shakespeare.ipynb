{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespeare.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOh4wh87/YmKgVXyPxIuDqG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zilleplus/MachineLearning/blob/main/Shakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "YmA9L3g1_ISw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sprF6clN-76m",
        "outputId": "2940df25-aab4-4fea-83ba-3359d986f0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "shakespeare_url = \"https://homl.info/shakespeare\"\n",
        "filepath = keras.utils.get_file(\"shakespear.text\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "  shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(shakespeare_text)"
      ],
      "metadata": {
        "id": "FKfkTQAQ_ZhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.texts_to_sequences([\"First\"]))\n",
        "print(tokenizer.sequences_to_texts([[20, 6,9,8,3]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO0KBBwz_qYj",
        "outputId": "d152b425-c20b-479c-e92b-c958c49f1d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[20, 6, 9, 8, 3]]\n",
            "['f i r s t']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text]))"
      ],
      "metadata": {
        "id": "p-kojwk7_9FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The windowed dataset, is a dataset of datasets\n",
        "for e in tf.data.Dataset.from_tensor_slices([1, 2, 3]).window(2):\n",
        "  print(\"This is a dataset:\")\n",
        "  print(e)\n",
        "  print(\"The dataset contains 2 elements:\")\n",
        "  for k in e:\n",
        "    print(k)\n",
        "  break\n",
        "print(\"----\")\n",
        "# used flat_map to transforms each window dataset into tensors, batch outputs \n",
        "# a iterator with one element, flat_map unravels to the single element.\n",
        "flat_data_example = tf.data.Dataset\\\n",
        "      .from_tensor_slices([1, 2, 3])\\\n",
        "      .window(2)\\\n",
        "      .flat_map(lambda window: window.batch(2))\n",
        "for e in flat_data_example:\n",
        "  print(e)\n",
        "print(type(flat_data_example))\n",
        "# notice the last tensor with [3], that does not have window lenght=2, this is why we enable drop_remainder"
      ],
      "metadata": {
        "id": "P1xn6XvP7nNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = encoded.size\n",
        "train_size = (dataset_size*90)//100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "n_steps = 100\n",
        "window_length = n_steps + 1 # Input shift 1 character ahead.\n",
        "dataset = dataset\\\n",
        "    .window(window_length, shift=1, drop_remainder=True)\\\n",
        "    .flat_map(lambda window: window.batch(window_length))"
      ],
      "metadata": {
        "id": "Q_XW98melTv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in dataset:\n",
        "  print(d)\n",
        "  break"
      ],
      "metadata": {
        "id": "oS2weZpi7YDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomize the data\n",
        "batch_size = 32\n",
        "dataset = dataset\\\n",
        "  .shuffle(10000)\\\n",
        "  .batch(batch_size)\\\n",
        "  .map(lambda windows: (windows[:, :-1], windows[:, 1:])) # split off the last element, the first dimension is batch, second is series"
      ],
      "metadata": {
        "id": "MmcBzfFt-yie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use one hot encoding\n",
        "max_id = len(tokenizer.word_index)\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ],
      "metadata": {
        "id": "WRjNp4IhAkTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add prefetch \n",
        "dataset = dataset.prefetch(buffer_size=1)"
      ],
      "metadata": {
        "id": "9Hf2tFHrFxrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "  keras.layers.GRU(units=128, return_sequences=True, dropout=0.2, input_shape=[None, max_id]), # recurrent_dropout=0.2\n",
        "  keras.layers.GRU(units=128, return_sequences=True, dropout=0.2), # recurrent_dropout=0.2\n",
        "  keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax')) # add softmax at the end to get [0,1] intervals\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, epochs=20)"
      ],
      "metadata": {
        "id": "OeKtmaIyGqgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find random samples from distribution p(0)=0.7 and p(1)=0.3\n",
        "tf.random.categorical(tf.math.log([[0.7, 0.3]]), 10)"
      ],
      "metadata": {
        "id": "o4Og8LGpJZ6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ecf840a-2b7d-4afb-bebe-67096a550524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=int64, numpy=array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}
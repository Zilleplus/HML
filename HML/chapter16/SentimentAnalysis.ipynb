{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcgGt0nXTz479AAWQFvMxL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zilleplus/MachineLearning/blob/main/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOz4eS4SQEdk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train) , (X_test, y_test) = keras.datasets.imdb.load_data()\n",
        "word_index = keras.datasets.imdb.get_word_index()"
      ],
      "metadata": {
        "id": "_PEsDRxvQMOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_train))\n",
        "print(type(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlT2QM92QTRS",
        "outputId": "8e028db5-973f-4521-ed2b-4b827ef63628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(word_index.keys())[0:10] # dict containing {word, id} pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DbabVDvQio8",
        "outputId": "ad3b0362-e21f-4393-9d0c-14d3934cc995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fawn',\n",
              " 'tsukino',\n",
              " 'nunnery',\n",
              " 'sonja',\n",
              " 'vani',\n",
              " 'woods',\n",
              " 'spiders',\n",
              " 'hanging',\n",
              " 'woody',\n",
              " 'trawling']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_word = {id_ + 3: word for word, id_ in word_index.items()}\n",
        "print(type(id_to_word)) # make the first 3 indices free to 0=padding token, 1=start-of-sequence, 2=unknown words (convention that is vaguely mentioned in the docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOqLmAJqRPB5",
        "outputId": "4cc00b1f-2637-4e48-a692-0e7b87582227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id_, token, in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  id_to_word[id_] = token"
      ],
      "metadata": {
        "id": "R7b5jlJnR4IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\" \".join([id_to_word[id_] for id_ in X_train[0][:10]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "20hrSEpZSqR8",
        "outputId": "5e0cbd01-bf3e-42b2-8f7a-2239c8419539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<sos> this film was just brilliant casting location scenery story'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do the preprocessing by hand, the keras version already has everything done."
      ],
      "metadata": {
        "id": "8uoNgvfVXTE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "M9k58M1GS5HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(X_batch, y_batch):\n",
        "  X_batch = tf.strings.substr(X_batch, 0, 300) # only take the first 300 chars\n",
        "  X_batch = tf.strings.regex_replace(X_batch, b\"<bv\\\\s*/?>\", b\" \") # remove all the breaks\n",
        "  X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \") # remove signs except the text, and replace them by spaces\n",
        "  X_batch = tf.strings.split(X_batch) # split up the sentence in words\n",
        "  return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
      ],
      "metadata": {
        "id": "7SdEyMz3UADv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove the most fequently used words, as they have very little meaning."
      ],
      "metadata": {
        "id": "8TISBt_WYm4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the number of occurences of the words\n",
        "from collections import Counter\n",
        "vocabulary = Counter()\n",
        "for X_batch, y_batch in datasets[\"train\"].batch(16).map(map_func=preprocessing):\n",
        "  for review in X_batch:\n",
        "    vocabulary.update(list(review.numpy()))\n",
        "print(\"The 3 most common words are:\"+str(vocabulary.most_common()[:3]))\n",
        "\n",
        "# reduce the verb size to 10000, as rarely used words are not that usefull.\n",
        "vocab_size = 10000\n",
        "truncated_vocabulary = [word for word, couint in vocabulary.most_common()[:vocab_size]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WmuR0puUbaR",
        "outputId": "0cb8e62b-1421-4616-cb98-8f7bbb2689fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 3 most common words are:[(b'<pad>', 176988), (b'the', 61137), (b'a', 38564)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Create a lookup table for the out-of-vocabulary (oov) buckets\n",
        " words = tf.constant(truncated_vocabulary)\n",
        " word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
        " vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
        " num_oov_buckets = 10000\n",
        " table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
      ],
      "metadata": {
        "id": "-Hg39y4eY0Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word faaaaantastic was not found in the table, soit was mapped on one of the oov buckets, \n",
        "# with an id greated than or equal to 10 000\n",
        "print(table.lookup(tf.constant([b\"This movie was faaaaantastic\".split()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-ZCK24tY0D1",
        "outputId": "eb7d61f1-d7b9-4cbf-aace-2f50b2e1cbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[   23    13    12 13791]], shape=(1, 4), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_words(X_batch, y_batch):\n",
        "  return table.lookup(X_batch), y_batch\n",
        "train_set = datasets[\"train\"].batch(32).map(preprocessing).prefetch(1)\n",
        "train_set = train_set.map(encode_words).prefetch(1)"
      ],
      "metadata": {
        "id": "rsvlqjQHcECg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 128\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size, input_shape=[None]),\n",
        "  keras.layers.GRU(units=128, return_sequences=True),\n",
        "  keras.layers.GRU(units=128),\n",
        "  keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnoZDK7pcMB5",
        "outputId": "96f284eb-952b-48d6-fbac-15d8c36f9030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 190s 237ms/step - loss: 0.5873 - accuracy: 0.6691\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 176s 225ms/step - loss: 0.3507 - accuracy: 0.8542\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 0.1883 - accuracy: 0.9338\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 174s 222ms/step - loss: 0.1111 - accuracy: 0.9627\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 132s 168ms/step - loss: 0.0749 - accuracy: 0.9749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets[\"test\"].batch(16).map(preprocessing).map(encode_words).prefetch(1)\n",
        "for x, y in test_data:\n",
        "    tf.print(x.shape)\n",
        "    y_pred = model.predict(x)\n",
        "    tf.print(y_pred)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfEPsZseki2X",
        "outputId": "a8d38f27-d100-4f32-890d-139c95cbafde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorShape([16, 60])\n",
            "array([[0.99798954],\n",
            "       [0.93247104],\n",
            "       [0.00501662],\n",
            "       [0.01496071],\n",
            "       [0.84784806],\n",
            "       [0.8968861 ],\n",
            "       [0.99513656],\n",
            "       [0.99939847],\n",
            "       [0.06936654],\n",
            "       [0.00429186],\n",
            "       [0.9842895 ],\n",
            "       [0.01469716],\n",
            "       [0.74352026],\n",
            "       [0.9943054 ],\n",
            "       [0.57256967],\n",
            "       [0.02385691]], dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh5ysFDioqRC",
        "outputId": "b90f4ab4-3807-47dd-880a-684a942870fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.9962 - accuracy: 0.7069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx8GI6hMrxXf",
        "outputId": "0b5d669f-2e37-43f3-977b-c5eddd6b2ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss, test acc: [0.9961671233177185, 0.7068799734115601]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = keras.backend\n",
        "inputs = keras.layers.Input(shape=[None])\n",
        "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n",
        "z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size)(inputs)\n",
        "z = keras.layers.GRU(units=128, return_sequences=True)(z, mask=mask)\n",
        "z = keras.layers.GRU(units=128)(z, mask=mask)\n",
        "outputs = keras.layers.Dense(units=1, activation=\"sigmoid\")(z)\n",
        "model = keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, epochs=5)"
      ],
      "metadata": {
        "id": "H00HQZHKs_H0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1476b752-d7fc-4eb0-d379-d4fed6521d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 163s 194ms/step - loss: 0.5319 - accuracy: 0.7267\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 161s 205ms/step - loss: 0.3078 - accuracy: 0.8766\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 151s 194ms/step - loss: 0.1527 - accuracy: 0.9463\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 154s 196ms/step - loss: 0.0955 - accuracy: 0.9669\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 151s 193ms/step - loss: 0.0624 - accuracy: 0.9783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUWc5A4YpH8B",
        "outputId": "b56b5d7e-acd4-452e-8dee-cd6cf93966ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 51s 30ms/step - loss: 1.1266 - accuracy: 0.7002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDWuryENqODI",
        "outputId": "9c83e5fa-8396-48ad-abf7-f0c817130255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss, test acc: [1.1266433000564575, 0.7002400159835815]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "hEas-akqqPkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "                          hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\",input_shape=[], dtype=tf.string),\n",
        "                          keras.layers.Dense(units=128, activation=\"relu\"),\n",
        "                          keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "0CidMb61BwlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = datasets[\"train\"].batch(32).prefetch(1)\n",
        "history = model.fit(train_set, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8o_IlJ5CHUj",
        "outputId": "dd5a60b7-1bdf-4b6a-8f4b-9755e33cfd02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 9s 10ms/step - loss: 0.5466 - accuracy: 0.7248\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5132 - accuracy: 0.7492\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5080 - accuracy: 0.7520\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5046 - accuracy: 0.7536\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5017 - accuracy: 0.7558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(datasets[\"test\"].batch(32).prefetch(1))\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnzGuWltC2E7",
        "outputId": "d1246bb6-ec60-496d-8fdc-3622c1ad37af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5112 - accuracy: 0.7477\n",
            "test loss, test acc: [0.5111663341522217, 0.7476800084114075]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PDsT8tscDAbh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}